import streamlit as st
import pandas as pd
import numpy as np
from openai import OpenAI
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min
import io
import plotly.express as px
import plotly.graph_objects as go

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="NPS Insights Carglass", layout="wide")
st.title("ğŸ“Š AnÃ¡lise Inteligente de ComentÃ¡rios NPS - CarGlass")

# ConfiguraÃ§Ã£o da API OpenAI
try:
    # Tenta diferentes nomes de chave que podem estar nos secrets
    api_key = None
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
    elif "openai_api_key" in st.secrets:
        api_key = st.secrets["openai_api_key"]
    elif "OPENAI_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_KEY"]
    
    if api_key is None:
        st.error("ğŸ”‘ Chave da API OpenAI nÃ£o encontrada. Verifique o arquivo .streamlit/secrets.toml")
        st.info("ğŸ’¡ Certifique-se de que a chave estÃ¡ definida como: OPENAI_API_KEY = 'sua_chave_aqui'")
        st.stop()
    
    client = OpenAI(api_key=api_key)
    st.success("âœ… ConexÃ£o com OpenAI estabelecida!")
    
except Exception as e:
    st.error(f"ğŸ”‘ Erro ao configurar OpenAI: {str(e)}")
    st.stop()


def classificar_nps(nota):
    """Classifica a nota NPS em Promotor, Neutro ou Detrator"""
    try:
        nota = float(nota)
        if nota >= 9:
            return "Promotor"
        elif nota >= 7:
            return "Neutro"
        else:
            return "Detrator"
    except (ValueError, TypeError):
        return "NÃ£o classificado"


def classificar_termometro_cliente(nota, comentario):
    """
    Classifica o estado emocional do cliente baseado na nota e comentÃ¡rio
    """
    try:
        nota = float(nota)
        comentario_lower = str(comentario).lower()
        
        # Palavras-chave para diferentes estados emocionais
        palavras_extremamente_insatisfeito = [
            'pÃ©ssimo', 'horrÃ­vel', 'terrÃ­vel', 'inaceitÃ¡vel', 'revoltante', 
            'indignado', 'furioso', 'nunca mais', 'decepcionante', 'absurdo',
            'inadmissÃ­vel', 'desrespeitoso', 'lamentÃ¡vel', 'vergonhoso'
        ]
        
        palavras_atritado = [
            'demorou', 'demora', 'atraso', 'problema', 'dificuldade', 
            'insatisfeito', 'chateado', 'irritado', 'complicado', 'difÃ­cil',
            'transtorno', 'erro', 'falha', 'ruim', 'desorganizado'
        ]
        
        palavras_feliz = [
            'excelente', 'Ã³timo', 'perfeito', 'maravilhoso', 'satisfeito',
            'rÃ¡pido', 'eficiente', 'bom atendimento', 'parabÃ©ns', 'recomendo',
            'tudo certo', 'nota 10', 'muito bom', 'adorei', 'fantÃ¡stico'
        ]
        
        # Verifica palavras no comentÃ¡rio
        tem_palavras_extremas = any(palavra in comentario_lower for palavra in palavras_extremamente_insatisfeito)
        tem_palavras_atrito = any(palavra in comentario_lower for palavra in palavras_atritado)
        tem_palavras_feliz = any(palavra in comentario_lower for palavra in palavras_feliz)
        
        # LÃ³gica de classificaÃ§Ã£o
        if nota <= 2 or tem_palavras_extremas:
            return "ğŸ˜¡ Extremamente Insatisfeito"
        elif nota <= 6 or (tem_palavras_atrito and not tem_palavras_feliz):
            return "ğŸ˜¤ Atritado"
        elif nota >= 9 or tem_palavras_feliz:
            return "ğŸ˜Š Feliz"
        elif nota >= 7:
            return "ğŸ˜ Neutro"
        else:
            return "ğŸ˜¤ Atritado"
            
    except Exception as e:
        return "â“ NÃ£o classificado"


def encontrar_pior_comentario_com_os(df):
    """
    Encontra o pior comentÃ¡rio (menor nota) e identifica a Ordem de ServiÃ§o
    """
    try:
        # Ordena por nota (crescente) para pegar o pior
        df_ordenado = df.sort_values(['Nota', 'Classificacao_NPS'], 
                                   ascending=[True, False]).reset_index(drop=True)
        
        if len(df_ordenado) == 0:
            return None, None, None, None
        
        pior_linha = df_ordenado.iloc[0]
        
        pior_nota = pior_linha['Nota']
        pior_comentario = pior_linha['Comentario']
        order_id = pior_linha.get('OrderId', 'N/A')
        classificacao_emocional = classificar_termometro_cliente(pior_nota, pior_comentario)
        
        return pior_nota, pior_comentario, order_id, classificacao_emocional
        
    except Exception as e:
        st.error(f"Erro ao encontrar pior comentÃ¡rio: {str(e)}")
        return None, None, None, None


def criar_termometro_visual(df_filtrado):
    """
    Cria um termÃ´metro visual mostrando a distribuiÃ§Ã£o emocional dos clientes
    """
    if len(df_filtrado) == 0:
        return None
    
    # Aplica classificaÃ§Ã£o emocional para todos os registros
    df_temp = df_filtrado.copy()
    df_temp['Termometro_Cliente'] = df_temp.apply(
        lambda row: classificar_termometro_cliente(row['Nota'], row['Comentario']), 
        axis=1
    )
    
    # Conta distribuiÃ§Ã£o
    distribuicao = df_temp['Termometro_Cliente'].value_counts()
    
    # Cores para cada estado emocional
    cores = {
        'ğŸ˜¡ Extremamente Insatisfeito': '#8B0000',  # Vermelho escuro
        'ğŸ˜¤ Atritado': '#FF6347',                   # Tomate
        'ğŸ˜ Neutro': '#FFD700',                     # Dourado
        'ğŸ˜Š Feliz': '#32CD32'                       # Verde lima
    }
    
    # Cria grÃ¡fico de termÃ´metro
    fig = go.Figure()
    
    # Dados para o grÃ¡fico
    labels = distribuicao.index.tolist()
    values = distribuicao.values.tolist()
    colors = [cores.get(label, '#808080') for label in labels]
    
    fig.add_trace(go.Bar(
        y=labels,
        x=values,
        orientation='h',
        marker=dict(color=colors),
        text=[f'{val} ({val/len(df_filtrado)*100:.1f}%)' for val in values],
        textposition='auto',
    ))
    
    fig.update_layout(
        title="ğŸŒ¡ï¸ TermÃ´metro Emocional dos Clientes",
        xaxis_title="Quantidade de Clientes",
        yaxis_title="Estado Emocional",
        height=400,
        showlegend=False
    )
    
    return fig, df_temp


def detectar_problemas_csv(df):
    """Detecta e corrige problemas comuns em arquivos CSV"""
    problemas = []
    
    # Verifica colunas duplicadas
    if df.columns.duplicated().any():
        problemas.append("Colunas duplicadas detectadas")
        df = df.loc[:, ~df.columns.duplicated()]
    
    # Verifica se hÃ¡ muitas colunas vazias
    colunas_vazias = df.columns[df.isnull().all()].tolist()
    if colunas_vazias:
        problemas.append(f"Colunas completamente vazias: {len(colunas_vazias)}")
        df = df.drop(columns=colunas_vazias)
    
    # Remove linhas completamente vazias
    linhas_antes = len(df)
    df = df.dropna(how='all')
    linhas_removidas = linhas_antes - len(df)
    if linhas_removidas > 0:
        problemas.append(f"Linhas vazias removidas: {linhas_removidas}")
    
    return df, problemas


def limpar_dados(df):
    """Limpa e padroniza os dados do DataFrame"""
    # Converte colunas para string para evitar problemas de tipo
    colunas_texto = ["Comentario", "Motivo_Selecionado", "Tipo_Questao"]
    for col in colunas_texto:
        if col in df.columns:
            df[col] = df[col].astype(str)
            df[col] = df[col].replace('nan', '')
            df[col] = df[col].replace('<NA>', '')
    
    # Limpa e converte a coluna de nota
    if "Nota" in df.columns:
        df["Nota"] = pd.to_numeric(df["Nota"], errors="coerce")
        df = df.dropna(subset=["Nota"])
        df["Nota"] = df["Nota"].astype(int)
    
    return df


def gerar_embeddings_lote(textos, tamanho_lote=20):
    """Gera embeddings em lotes menores para evitar problemas"""
    try:
        todos_embeddings = []
        total_lotes = (len(textos) - 1) // tamanho_lote + 1
        
        # Cria um container fixo para o progresso
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        for i in range(0, len(textos), tamanho_lote):
            lote = textos[i:i+tamanho_lote]
            lote_atual = i // tamanho_lote + 1
            
            # Atualiza progresso sem mover a tela
            progress = lote_atual / total_lotes
            progress_bar.progress(progress)
            status_text.text(f"ğŸ¤– Processando lote {lote_atual} de {total_lotes} ({len(lote)} comentÃ¡rios)")
            
            response = client.embeddings.create(
                input=lote,
                model="text-embedding-ada-002"
            )
            
            lote_embeddings = [embedding.embedding for embedding in response.data]
            todos_embeddings.extend(lote_embeddings)
        
        # Limpa o progresso
        progress_container.empty()
        return todos_embeddings
        
    except Exception as e:
        st.error(f"Erro no processamento em lotes: {str(e)}")
        return None


def gerar_embeddings(textos):
    """Gera embeddings dos textos usando OpenAI"""
    try:
        # Limpa e valida os textos de forma mais rigorosa
        textos_limpos = []
        for i, texto in enumerate(textos):
            # Converte para string e limpa
            texto_str = str(texto).strip()
            
            # Remove caracteres problemÃ¡ticos
            texto_limpo = texto_str.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
            # Remove caracteres de controle
            texto_limpo = ''.join(char for char in texto_limpo if ord(char) >= 32 or char in '\n\r\t')
            
            # Limita tamanho (OpenAI tem limite de tokens)
            if len(texto_limpo) > 8000:
                texto_limpo = texto_limpo[:8000]
            
            # SÃ³ adiciona se tiver conteÃºdo vÃ¡lido
            if len(texto_limpo.strip()) >= 10:
                textos_limpos.append(texto_limpo.strip())
        
        if not textos_limpos:
            st.error("âŒ Nenhum texto vÃ¡lido encontrado para anÃ¡lise.")
            return None
        
        # Container fixo para status
        status_container = st.container()
        with status_container:
            st.info(f"ğŸ”„ Iniciando processamento de {len(textos_limpos)} comentÃ¡rios...")
        
        # Tenta com lotes menores se houver muitos textos
        if len(textos_limpos) > 50:
            result = gerar_embeddings_lote(textos_limpos, tamanho_lote=20)
        else:
            # Para quantidades menores, processa tudo de uma vez
            try:
                response = client.embeddings.create(
                    input=textos_limpos,
                    model="text-embedding-ada-002"
                )
                result = [embedding.embedding for embedding in response.data]
                
            except Exception as api_error:
                st.warning(f"âš ï¸ Tentando processamento em lotes menores...")
                result = gerar_embeddings_lote(textos_limpos, tamanho_lote=10)
        
        # Atualiza status final
        status_container.empty()
        if result:
            st.success(f"âœ… Embeddings gerados com sucesso para {len(result)} textos!")
        
        return result
        
    except Exception as e:
        st.error(f"Erro geral ao gerar embeddings: {str(e)}")
        return None


def sugerir_motivos_por_cluster(df_filtrado, n_clusters=8):
    """Analisa os comentÃ¡rios e sugere novos motivos baseados em clustering"""
    try:
        # Filtra comentÃ¡rios vÃ¡lidos
        df_valido = df_filtrado.copy()
        df_valido = df_valido.dropna(subset=["Comentario"])
        
        # Converte comentÃ¡rios para string e filtra vÃ¡lidos
        df_valido["Comentario"] = df_valido["Comentario"].astype(str)
        
        # Filtra comentÃ¡rios vÃ¡lidos com validaÃ§Ã£o mais rigorosa
        mask_validos = (
            (df_valido["Comentario"] != '') & 
            (df_valido["Comentario"] != 'nan') &
            (df_valido["Comentario"] != 'None') &
            (df_valido["Comentario"].str.len() > 10) &
            (df_valido["Comentario"].str.strip() != '')
        )
        df_valido = df_valido[mask_validos].reset_index(drop=True)
        
        if len(df_valido) < 2:
            st.error("âŒ NÃºmero insuficiente de comentÃ¡rios vÃ¡lidos para anÃ¡lise.")
            st.info("ğŸ’¡ Dica: Verifique se hÃ¡ comentÃ¡rios com pelo menos 10 caracteres no dataset filtrado.")
            return None, None
        
        if len(df_valido) < n_clusters:
            st.warning(f"âš ï¸ ComentÃ¡rios disponÃ­veis ({len(df_valido)}) menor que clusters solicitados ({n_clusters}). Ajustando para {max(2, len(df_valido)//2)} clusters.")
            n_clusters = max(2, len(df_valido)//2)
        
        # Prepara lista de textos limpos
        textos = []
        indices_validos = []
        
        for idx, comentario in enumerate(df_valido["Comentario"]):
            texto_limpo = str(comentario).strip()
            if len(texto_limpo) > 10:  # ValidaÃ§Ã£o extra
                textos.append(texto_limpo)
                indices_validos.append(idx)
        
        if len(textos) < 2:
            st.error("âŒ Nenhum comentÃ¡rio vÃ¡lido encontrado apÃ³s limpeza.")
            return None, None
            
        st.info(f"ğŸ“Š Analisando {len(textos)} comentÃ¡rios vÃ¡lidos em {n_clusters} grupos.")
        
        # Gera embeddings
        with st.spinner("ğŸ¤– Gerando embeddings com OpenAI..."):
            embeddings = gerar_embeddings(textos)
        
        if embeddings is None or len(embeddings) == 0:
            return None, None
        
        # Aplica clustering
        with st.spinner("ğŸ” Realizando anÃ¡lise de clusters..."):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(embeddings)
        
        # Cria DataFrame final apenas com textos que foram processados
        df_final = df_valido.iloc[indices_validos].copy()
        df_final.loc[:, "Cluster"] = labels
        
        # Encontra comentÃ¡rios representativos
        representantes_idx, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)
        
        motivos = []
        for i, idx in enumerate(representantes_idx):
            try:
                linha = df_final.iloc[idx]
                comentario_repr = linha["Comentario"]
                classificacao = linha["Classificacao_NPS"]
                
                # Cria sugestÃ£o de motivo mais concisa
                comentario_str = str(comentario_repr).strip()
                if len(comentario_str) > 120:
                    sugestao = comentario_str[:117] + "..."
                else:
                    sugestao = comentario_str
                
                # Conta quantos comentÃ¡rios estÃ£o neste cluster
                count_cluster = len(df_final[df_final["Cluster"] == i])
                
                motivos.append({
                    "Cluster": f"Grupo {i+1}",
                    "Classificacao_NPS": classificacao,
                    "ComentÃ¡rio Representativo": sugestao,
                    "Quantidade de ComentÃ¡rios": count_cluster
                })
            except Exception as e:
                st.warning(f"âš ï¸ Erro ao processar cluster {i+1}: {str(e)}")
                continue
        
        if not motivos:
            st.error("âŒ NÃ£o foi possÃ­vel gerar motivos representativos.")
            return None, None
            
        resultado_sugestoes = pd.DataFrame(motivos).sort_values("Cluster")
        return resultado_sugestoes, df_final
    
    except Exception as e:
        st.error(f"Erro na anÃ¡lise de clusters: {str(e)}")
        return None, None


def gerar_dashboard_termometro(df_filtrado):
    """
    Gera um dashboard completo com termÃ´metro emocional e anÃ¡lise da OS crÃ­tica
    """
    st.markdown("---")
    st.markdown("## ğŸŒ¡ï¸ Dashboard TermÃ´metro Emocional")
    
    # Aplica classificaÃ§Ã£o emocional
    df_temp = df_filtrado.copy()
    df_temp['Termometro_Cliente'] = df_temp.apply(
        lambda row: classificar_termometro_cliente(row['Nota'], row['Comentario']), 
        axis=1
    )
    
    # Cria o termÃ´metro visual
    fig_termometro, df_com_termometro = criar_termometro_visual(df_filtrado)
    
    # Layout em colunas
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if fig_termometro:
            st.plotly_chart(fig_termometro, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ“Š Resumo Emocional")
        
        # MÃ©tricas resumidas
        total = len(df_temp)
        
        # Conta cada tipo
        extremo = len(df_temp[df_temp['Termometro_Cliente'] == 'ğŸ˜¡ Extremamente Insatisfeito'])
        atritado = len(df_temp[df_temp['Termometro_Cliente'] == 'ğŸ˜¤ Atritado'])
        neutro = len(df_temp[df_temp['Termometro_Cliente'] == 'ğŸ˜ Neutro'])
        feliz = len(df_temp[df_temp['Termometro_Cliente'] == 'ğŸ˜Š Feliz'])
        
        # Mostra mÃ©tricas
        st.metric("ğŸ˜¡ Extremamente Insatisfeito", 
                 f"{extremo}", 
                 f"{extremo/total*100:.1f}%" if total > 0 else "0%")
        
        st.metric("ğŸ˜¤ Atritado", 
                 f"{atritado}", 
                 f"{atritado/total*100:.1f}%" if total > 0 else "0%")
        
        st.metric("ğŸ˜ Neutro", 
                 f"{neutro}", 
                 f"{neutro/total*100:.1f}%" if total > 0 else "0%")
        
        st.metric("ğŸ˜Š Feliz", 
                 f"{feliz}", 
                 f"{feliz/total*100:.1f}%" if total > 0 else "0%")
    
    # SeÃ§Ã£o do pior comentÃ¡rio
    st.markdown("### ğŸš¨ AnÃ¡lise do Cliente Mais CrÃ­tico")
    
    pior_nota, pior_comentario, order_id, classificacao_emocional = encontrar_pior_comentario_com_os(df_filtrado)
    
    if pior_nota is not None:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ğŸ“‰ Pior Nota", f"{pior_nota}")
        
        with col2:
            st.metric("ğŸ¯ Ordem de ServiÃ§o", f"{order_id}")
        
        with col3:
            st.metric("ğŸŒ¡ï¸ Estado Emocional", classificacao_emocional)
        
        # Exibe o comentÃ¡rio em destaque
        st.markdown("#### ğŸ’¬ ComentÃ¡rio Mais CrÃ­tico:")
        st.error(f"**OS {order_id}:** {pior_comentario}")
        
        # RecomendaÃ§Ãµes para este caso
        st.markdown("#### âš¡ AÃ§Ãµes Recomendadas para esta OS:")
        acoes_criticas = [
            f"ğŸ”¥ **URGENTE**: Contatar cliente da OS {order_id} imediatamente",
            "ğŸ“ **LigaÃ§Ã£o direta**: Gerente deve fazer contato pessoal",
            "ğŸ¯ **ResoluÃ§Ã£o**: Oferecer soluÃ§Ã£o imediata e compensaÃ§Ã£o",
            "ğŸ“ **Follow-up**: Acompanhar satisfaÃ§Ã£o apÃ³s resoluÃ§Ã£o",
            "ğŸ” **InvestigaÃ§Ã£o**: Analisar processo que gerou este problema"
        ]
        
        for acao in acoes_criticas:
            st.markdown(acao)
    else:
        st.info("â„¹ï¸ NÃ£o foi possÃ­vel identificar o comentÃ¡rio mais crÃ­tico.")
    
    return df_com_termometro


def gerar_relatorio_detalhado(df_filtrado, sugestoes, df_final):
    """Gera um relatÃ³rio detalhado da anÃ¡lise para apresentaÃ§Ã£o Ã  diretoria"""
    
    st.markdown("---")
    st.markdown("## ğŸ“Š RelatÃ³rio Executivo da AnÃ¡lise NPS")
    
    # MÃ©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_comentarios = len(df_filtrado)
        st.metric("ğŸ“ Total Analisado", f"{total_comentarios:,}")
    
    with col2:
        promotores = len(df_filtrado[df_filtrado["Classificacao_NPS"] == "Promotor"])
        perc_promotores = (promotores/total_comentarios)*100 if total_comentarios > 0 else 0
        st.metric("ğŸ‘ Promotores", f"{promotores:,}", f"{perc_promotores:.1f}%")
    
    with col3:
        detratores = len(df_filtrado[df_filtrado["Classificacao_NPS"] == "Detrator"])
        perc_detratores = (detratores/total_comentarios)*100 if total_comentarios > 0 else 0
        st.metric("ğŸ‘ Detratores", f"{detratores:,}", f"{perc_detratores:.1f}%")
    
    with col4:
        nps_score = perc_promotores - perc_detratores
        st.metric("ğŸ¯ NPS Score", f"{nps_score:.1f}")
    
    # AnÃ¡lise por cluster
    st.markdown("### ğŸ” AnÃ¡lise Detalhada por Grupo")
    
    # Cria tabs para diferentes anÃ¡lises
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ Resumo Grupos", "ğŸ“ˆ AnÃ¡lise Quantitativa", "ğŸ’¬ ComentÃ¡rios Representativos", "ğŸ“Š DistribuiÃ§Ã£o"])
    
    with tab1:
        st.markdown("#### Grupos Identificados pela IA")
        
        # Adiciona mais colunas Ã  tabela de sugestÃµes
        sugestoes_expandidas = sugestoes.copy()
        sugestoes_expandidas["% do Total"] = (sugestoes_expandidas["Quantidade de ComentÃ¡rios"] / total_comentarios * 100).round(1)
        
        # Reordena as colunas
        sugestoes_display = sugestoes_expandidas[["Cluster", "Classificacao_NPS", "Quantidade de ComentÃ¡rios", "% do Total", "ComentÃ¡rio Representativo"]]
        
        st.dataframe(sugestoes_display, use_container_width=True, hide_index=True)
    
    with tab2:
        st.markdown("#### DistribuiÃ§Ã£o por ClassificaÃ§Ã£o NPS")
        
        # AnÃ¡lise por classificaÃ§Ã£o
        analise_nps = df_filtrado.groupby("Classificacao_NPS").size().reset_index(name="Quantidade")
        analise_nps["Percentual"] = (analise_nps["Quantidade"] / total_comentarios * 100).round(1)
        
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(analise_nps, hide_index=True)
        
        with col2:
            # Principais motivos atuais
            if "Motivo_Selecionado" in df_filtrado.columns:
                top_motivos = df_filtrado["Motivo_Selecionado"].value_counts().head(5)
                st.markdown("**Top 5 Motivos Atuais:**")
                for motivo, count in top_motivos.items():
                    perc = (count/total_comentarios)*100
                    st.write(f"â€¢ {motivo}: {count} ({perc:.1f}%)")
    
    with tab3:
        st.markdown("#### ComentÃ¡rios Mais Representativos por Grupo")
        
        for _, row in sugestoes.iterrows():
            cluster_num = int(row["Cluster"].split()[-1])
            comentarios_cluster = df_final[df_final["Cluster"] == cluster_num-1]
            
            with st.expander(f"{row['Cluster']} - {row['Classificacao_NPS']} ({row['Quantidade de ComentÃ¡rios']} comentÃ¡rios)"):
                st.write(f"**ComentÃ¡rio Principal:** {row['ComentÃ¡rio Representativo']}")
                
                # Mostra mais alguns comentÃ¡rios do cluster
                if len(comentarios_cluster) > 1:
                    st.write("**Outros comentÃ¡rios similares:**")
                    outros_comentarios = comentarios_cluster["Comentario"].head(3).tolist()
                    for i, comentario in enumerate(outros_comentarios[:3], 1):
                        if comentario != row["ComentÃ¡rio Representativo"]:
                            st.write(f"{i}. {str(comentario)[:150]}...")
    
    with tab4:
        st.markdown("#### AnÃ¡lise de DistribuiÃ§Ã£o")
        
        # Cria visualizaÃ§Ã£o dos grupos
        # GrÃ¡fico de barras dos grupos
        fig_grupos = px.bar(
            sugestoes_expandidas, 
            x="Cluster", 
            y="Quantidade de ComentÃ¡rios",
            color="Classificacao_NPS",
            title="DistribuiÃ§Ã£o de ComentÃ¡rios por Grupo",
            color_discrete_map={
                "Promotor": "#2E8B57",
                "Neutro": "#FFD700", 
                "Detrator": "#DC143C"
            }
        )
        st.plotly_chart(fig_grupos, use_container_width=True)
        
        # Insights principais
        st.markdown("#### ğŸ¯ Principais Insights")
        
        grupo_maior = sugestoes_expandidas.loc[sugestoes_expandidas["Quantidade de ComentÃ¡rios"].idxmax()]
        grupo_detrator = sugestoes_expandidas[sugestoes_expandidas["Classificacao_NPS"] == "Detrator"]
        
        insights = [
            f"â€¢ **Maior grupo identificado:** {grupo_maior['Cluster']} com {grupo_maior['Quantidade de ComentÃ¡rios']:,} comentÃ¡rios ({grupo_maior['% do Total']:.1f}% do total)"
        ]
        
        # Destaque especial para grupos de detratores
        if not grupo_detrator.empty:
            # Encontra o maior grupo de detratores
            maior_detrator = grupo_detrator.loc[grupo_detrator["Quantidade de ComentÃ¡rios"].idxmax()]
            total_detratores_grupos = grupo_detrator["Quantidade de ComentÃ¡rios"].sum()
            perc_detratores_grupos = (total_detratores_grupos / total_comentarios) * 100
            
            insights.extend([
                f"â€¢ **ğŸš¨ ALERTA CRÃTICO - {maior_detrator['Cluster']}:** {maior_detrator['Quantidade de ComentÃ¡rios']:,} detratores ({(maior_detrator['Quantidade de ComentÃ¡rios']/total_comentarios)*100:.1f}%)",
                f"  â””â”€ **Problema:** {maior_detrator['ComentÃ¡rio Representativo']}",
                f"â€¢ **Total de grupos de detratores:** {len(grupo_detrator)} grupos com {total_detratores_grupos:,} comentÃ¡rios ({perc_detratores_grupos:.1f}%)",
                f"â€¢ **ClassificaÃ§Ã£o predominante:** {sugestoes['Classificacao_NPS'].mode()[0]}"
            ])
        else:
            insights.append(f"â€¢ **ClassificaÃ§Ã£o predominante:** {sugestoes['Classificacao_NPS'].mode()[0]}")
        
        insights.append(f"â€¢ **NPS Score atual:** {nps_score:.1f} ({'Excelente' if nps_score >= 50 else 'Bom' if nps_score >= 0 else 'Ruim'})")
        
        for insight in insights:
            if "ğŸš¨ ALERTA CRÃTICO" in insight:
                st.markdown(f"<div style='background-color: #ffebee; padding: 10px; border-radius: 5px; border-left: 5px solid #f44336;'>{insight}</div>", unsafe_allow_html=True)
            else:
                st.markdown(insight)
        
        # RecomendaÃ§Ãµes
        st.markdown("#### ğŸ’¡ RecomendaÃ§Ãµes EstratÃ©gicas")
        
        recomendacoes = [
            "ğŸ“Œ **Manter pontos fortes:** ReforÃ§ar prÃ¡ticas que geram comentÃ¡rios positivos nos grupos de promotores",
            "ğŸ¯ **Focar em melhorias:** Priorizar aÃ§Ãµes corretivas nos grupos de detratores identificados",
            "ğŸ“Š **Monitoramento contÃ­nuo:** Implementar acompanhamento regular usando estes grupos como baseline",
            "ğŸ”„ **AtualizaÃ§Ã£o de motivos:** Considerar substituir motivos atuais pelos sugeridos pela IA para maior precisÃ£o"
        ]
        
        for rec in recomendacoes:
            st.markdown(rec)
    
    return sugestoes_expandidas


def gerar_analise_detratores(df_filtrado, df_final):
    """Gera anÃ¡lise especÃ­fica e detalhada dos detratores"""
    
    detratores = df_filtrado[df_filtrado["Classificacao_NPS"] == "Detrator"]
    
    if len(detratores) == 0:
        st.info("âœ… Nenhum detrator encontrado nos dados filtrados.")
        return
    
    st.markdown("---")
    st.markdown("## ğŸš¨ AnÃ¡lise CrÃ­tica de Detratores")
    st.markdown("*Esta seÃ§Ã£o foca nos clientes mais insatisfeitos para aÃ§Ãµes prioritÃ¡rias*")
    
    # MÃ©tricas crÃ­ticas
    col1, col2, col3, col4 = st.columns(4)
    
    total_detratores = len(detratores)
    total_geral = len(df_filtrado)
    perc_detratores = (total_detratores / total_geral) * 100
    
    with col1:
        st.metric("ğŸ”¥ Total Detratores", f"{total_detratores:,}", f"{perc_detratores:.1f}% do total")
    
    with col2:
        nota_media = detratores["Nota"].mean()
        st.metric("ğŸ“‰ Nota MÃ©dia", f"{nota_media:.1f}", "CrÃ­tico se < 5")
    
    with col3:
        notas_zero = len(detratores[detratores["Nota"] == 0])
        perc_zero = (notas_zero / total_detratores) * 100 if total_detratores > 0 else 0
        st.metric("ğŸ’¥ Notas 0", f"{notas_zero}", f"{perc_zero:.1f}%")
    
    with col4:
        if df_final is not None and "Cluster" in df_final.columns:
            clusters_detratores = len(df_final[df_final["Classificacao_NPS"] == "Detrator"]["Cluster"].unique())
            st.metric("ğŸ¯ Grupos Detratores", clusters_detratores)
        else:
            st.metric("ğŸ¯ Grupos Detratores", "N/A")
    
    # Tabs para anÃ¡lise detalhada
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”¥ Principais Problemas", "ğŸ“Š DistribuiÃ§Ã£o", "ğŸ’¬ ComentÃ¡rios CrÃ­ticos", "âš¡ Plano de AÃ§Ã£o"])
    
    with tab1:
        st.markdown("### ğŸ¯ Principais Motivos de InsatisfaÃ§Ã£o")
        
        if "Motivo_Selecionado" in detratores.columns:
            # Top problemas dos detratores
            problemas = detratores["Motivo_Selecionado"].value_counts().head(10)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("#### Top 10 Motivos de Detratores")
                for i, (motivo, count) in enumerate(problemas.items(), 1):
                    perc = (count / total_detratores) * 100
                    
                    # Destaca o principal problema
                    if i == 1:
                        st.markdown(f"**ğŸ”´ {i}. {motivo}**")
                        st.markdown(f"   ğŸ“Š **{count:,} casos ({perc:.1f}% dos detratores)**")
                        st.markdown(f"   ğŸš¨ **PRIORIDADE MÃXIMA**")
                    elif i <= 3:
                        st.markdown(f"**ğŸŸ¡ {i}. {motivo}**")
                        st.markdown(f"   ğŸ“Š {count:,} casos ({perc:.1f}%)")
                    else:
                        st.markdown(f"{i}. {motivo}: {count:,} casos ({perc:.1f}%)")
            
            with col2:
                # AnÃ¡lise do problema principal
                problema_principal = problemas.index[0]
                casos_principais = detratores[detratores["Motivo_Selecionado"] == problema_principal]
                
                st.markdown("#### ğŸ” AnÃ¡lise do Problema #1")
                st.metric("Casos", len(casos_principais))
                
                if len(casos_principais) > 0:
                    nota_media_problema = casos_principais["Nota"].mean()
                    st.metric("Nota MÃ©dia", f"{nota_media_problema:.1f}")
                    
                    # DistribuiÃ§Ã£o de notas do problema principal
                    distribuicao_notas = casos_principais["Nota"].value_counts().sort_index()
                    st.markdown("**DistribuiÃ§Ã£o de Notas:**")
                    for nota, count in distribuicao_notas.items():
                        st.write(f"Nota {nota}: {count} casos")
    
    with tab2:
        st.markdown("### ğŸ“ˆ DistribuiÃ§Ã£o e TendÃªncias")
        
        # GrÃ¡fico de distribuiÃ§Ã£o de notas dos detratores
        fig_notas = px.histogram(
            detratores, 
            x="Nota", 
            title="DistribuiÃ§Ã£o de Notas - Detratores",
            color_discrete_sequence=["#DC143C"]
        )
        fig_notas.update_layout(xaxis_title="Nota NPS", yaxis_title="Quantidade")
        st.plotly_chart(fig_notas, use_container_width=True)
        
        # AnÃ¡lise por tipo de questÃ£o se disponÃ­vel
        if "Tipo_Questao" in detratores.columns:
            st.markdown("#### ğŸ“‹ Detratores por Tipo de QuestÃ£o")
            tipo_questao = detratores["Tipo_Questao"].value_counts()
            
            fig_tipo = px.pie(
                values=tipo_questao.values,
                names=tipo_questao.index,
                title="DistribuiÃ§Ã£o de Detratores por Tipo"
            )
            st.plotly_chart(fig_tipo, use_container_width=True)
    
    with tab3:
        st.markdown("### ğŸ’¬ ComentÃ¡rios Mais CrÃ­ticos")
        
        # ComentÃ¡rios com notas 0-2 (mais crÃ­ticos)
        criticos = detratores[detratores["Nota"] <= 2].sort_values("Nota")
        
        if len(criticos) > 0:
            st.markdown(f"#### ğŸš¨ {len(criticos)} ComentÃ¡rios Extremamente CrÃ­ticos (Notas 0-2)")
            
            for idx, row in criticos.head(5).iterrows():
                with st.expander(f"Nota {row['Nota']} - OS: {row.get('OrderId', 'N/A')} - {row.get('Motivo_Selecionado', 'N/A')}"):
                    st.write(f"**ComentÃ¡rio:** {row['Comentario']}")
                    st.write(f"**Ordem de ServiÃ§o:** {row.get('OrderId', 'N/A')}")
                    if "Tipo_Questao" in row:
                        st.write(f"**Tipo:** {row['Tipo_Questao']}")
                    if "Companhia" in row:
                        st.write(f"**Seguradora:** {row['Companhia']}")
                    
                    # Mostra o termÃ´metro emocional deste comentÃ¡rio
                    estado_emocional = classificar_termometro_cliente(row['Nota'], row['Comentario'])
                    st.write(f"**Estado Emocional:** {estado_emocional}")
        
        # ComentÃ¡rios do maior grupo de detratores (se existir anÃ¡lise de clusters)
        st.markdown("#### ğŸ¯ ComentÃ¡rios do Maior Grupo de Detratores")
        if df_final is not None and "Cluster" in df_final.columns:
            detratores_clustered = df_final[df_final["Classificacao_NPS"] == "Detrator"]
            if len(detratores_clustered) > 0:
                maior_cluster = detratores_clustered["Cluster"].value_counts().index[0]
                comentarios_cluster = detratores_clustered[detratores_clustered["Cluster"] == maior_cluster]
                
                st.write(f"**Grupo {maior_cluster + 1} - {len(comentarios_cluster)} comentÃ¡rios**")
                for _, row in comentarios_cluster.head(3).iterrows():
                    st.write(f"â€¢ **OS {row.get('OrderId', 'N/A')}:** {str(row['Comentario'])[:200]}...")
        else:
            st.info("AnÃ¡lise de clusters nÃ£o disponÃ­vel para esta visualizaÃ§Ã£o.")
    
    with tab4:
        st.markdown("### âš¡ Plano de AÃ§Ã£o Imediato")
        
        st.markdown("#### ğŸš¨ AÃ§Ãµes PrioritÃ¡rias (0-30 dias)")
        
        acoes_imediatas = [
            "ğŸ¯ **Foco no problema #1**: Resolver urgentemente as dificuldades de agendamento",
            "ğŸ“ **Central de atendimento**: ReforÃ§ar treinamento da equipe para agendamentos",
            "ğŸ”§ **Sistema de agendamento**: Revisar e melhorar a plataforma/processo",
            "ğŸ“± **MÃºltiplos canais**: Facilitar agendamento por telefone, WhatsApp e site",
            "â° **Prazos claros**: Estabelecer SLA mÃ¡ximo para agendamento (ex: 24h)"
        ]
        
        for acao in acoes_imediatas:
            st.markdown(acao)
        
        st.markdown("#### ğŸ“ˆ AÃ§Ãµes de MÃ©dio Prazo (30-90 dias)")
        
        acoes_medio_prazo = [
            "ğŸª **ExpansÃ£o da rede**: Avaliar abertura de lojas em regiÃµes deficitÃ¡rias",
            "ğŸ¤– **AutomaÃ§Ã£o**: Implementar agendamento automÃ¡tico com confirmaÃ§Ã£o",
            "ğŸ“Š **Monitoramento**: Dashboard em tempo real dos agendamentos",
            "ğŸ“ **Treinamento**: CapacitaÃ§Ã£o contÃ­nua das equipes de atendimento",
            "ğŸ“ **Callback**: Sistema de retorno automÃ¡tico para casos nÃ£o resolvidos"
        ]
        
        for acao in acoes_medio_prazo:
            st.markdown(acao)
        
        # ROI estimado
        st.markdown("#### ğŸ’° Impacto Financeiro Estimado")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ğŸ’¸ Custo atual dos detratores:**")
            st.write(f"â€¢ {total_detratores:,} clientes insatisfeitos")
            st.write(f"â€¢ Potencial perda de receita")
            st.write(f"â€¢ Impacto na reputaÃ§Ã£o da marca")
        
        with col2:
            st.markdown("**ğŸ’¹ BenefÃ­cio da melhoria:**")
            st.write(f"â€¢ ConversÃ£o de {total_detratores//2:,} detratores em neutros")
            st.write(f"â€¢ Melhoria do NPS em ~{(total_detratores//2/total_geral)*100:.1f} pontos")
            st.write(f"â€¢ ReduÃ§Ã£o de reclamaÃ§Ãµes e cancelamentos")
    
    return detratores


# Interface principal
st.markdown("### ğŸ“ Upload do Arquivo")
uploaded_file = st.file_uploader(
    "Envie o arquivo Excel ou CSV com os comentÃ¡rios NPS:", 
    type=[".xlsx", ".csv"],
    help="O arquivo deve conter as colunas: OrderId, Companhia, Secao, Tipo_Questao, Nota, Motivo_Selecionado, Comentario"
)

if uploaded_file:
    try:
        # Leitura do arquivo
        with st.spinner("Carregando arquivo..."):
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file, encoding="utf-8")
            else:
                df = pd.read_excel(uploaded_file, header=1)

        # VerificaÃ§Ã£o e correÃ§Ã£o de problemas no CSV
        df, problemas = detectar_problemas_csv(df)
        if problemas:
            st.warning("âš ï¸ Problemas detectados e corrigidos:")
            for problema in problemas:
                st.write(f"â€¢ {problema}")

        # Mostra informaÃ§Ãµes bÃ¡sicas do arquivo
        st.info(f"ğŸ“ Arquivo carregado: {len(df)} linhas x {len(df.columns)} colunas")
        
        # Exibe as primeiras colunas para debug
        with st.expander("ğŸ” Visualizar estrutura do arquivo"):
            st.write("**Primeiras 10 colunas:**")
            st.write(list(df.columns[:10]))
            st.write("**Amostra dos dados:**")
            st.dataframe(df.head(3))

        # VerificaÃ§Ã£o de colunas mÃ­nimas
        if len(df.columns) < 7:
            st.error(f"âŒ O arquivo possui apenas {len(df.columns)} colunas. SÃ£o necessÃ¡rias pelo menos 7 colunas.")
            st.info("ğŸ“‹ Estrutura esperada: OrderId, Companhia, Secao, Tipo_Questao, Nota, Motivo_Selecionado, Comentario")
            st.stop()

        # RenomeaÃ§Ã£o das colunas
        try:
            col_renames = {
                df.columns[0]: "OrderId",
                df.columns[1]: "Companhia", 
                df.columns[2]: "Secao",
                df.columns[3]: "Tipo_Questao",
                df.columns[4]: "Nota",
                df.columns[5]: "Motivo_Selecionado",
                df.columns[6]: "Comentario"
            }
            
            if len(df.columns) > 8:
                col_renames[df.columns[8]] = "Grupo_Motivo"

            # Renomeia apenas as colunas que existem
            df_renamed = df.rename(columns=col_renames)
            
            # Verifica se o rename funcionou
            required_cols = ["OrderId", "Companhia", "Secao", "Tipo_Questao", "Nota", "Motivo_Selecionado", "Comentario"]
            missing_cols = [col for col in required_cols if col not in df_renamed.columns]
            
            if missing_cols:
                st.error(f"âŒ Colunas nÃ£o encontradas apÃ³s renomeaÃ§Ã£o: {missing_cols}")
                st.write("**Colunas disponÃ­veis:**", list(df.columns))
                st.stop()
            else:
                df = df_renamed
                
        except Exception as e:
            st.error(f"âŒ Erro na renomeaÃ§Ã£o das colunas: {str(e)}")
            st.write("**Estrutura atual do DataFrame:**")
            st.write(f"NÃºmero de colunas: {len(df.columns)}")
            st.write("Primeiras 10 colunas:", list(df.columns[:10]))
            st.stop()

        # SeleÃ§Ã£o das colunas essenciais
        try:
            colunas_essenciais = ["OrderId", "Companhia", "Secao", "Tipo_Questao", "Nota", "Motivo_Selecionado", "Comentario"]
            if "Grupo_Motivo" in df.columns:
                colunas_essenciais.append("Grupo_Motivo")

            # Verifica se todas as colunas essenciais existem
            colunas_existentes = [col for col in colunas_essenciais if col in df.columns]
            if len(colunas_existentes) < 7:
                st.error(f"âŒ Nem todas as colunas essenciais foram encontradas.")
                st.write("**Colunas encontradas:**", colunas_existentes)
                st.write("**Colunas necessÃ¡rias:**", colunas_essenciais[:7])
                st.stop()

            df = df[colunas_existentes]
            
        except Exception as e:
            st.error(f"âŒ Erro ao selecionar colunas essenciais: {str(e)}")
            st.stop()
        
        # Limpeza dos dados
        try:
            df = limpar_dados(df)
        except Exception as e:
            st.error(f"Erro na limpeza dos dados: {str(e)}")
            st.info("Tentando continuar com dados bÃ¡sicos...")
            # Limpeza mÃ­nima em caso de erro
            if "Nota" in df.columns:
                df["Nota"] = pd.to_numeric(df["Nota"], errors="coerce")
                df = df.dropna(subset=["Nota"])
            if "Comentario" in df.columns:
                df["Comentario"] = df["Comentario"].astype(str)
        
        # Remove linhas sem comentÃ¡rios
        df = df.dropna(subset=["Comentario"])
        df = df[df["Comentario"].astype(str) != '']
        df = df[df["Comentario"].astype(str) != 'nan']
        
        # Filtra comentÃ¡rios com tamanho mÃ­nimo
        mask_comentarios_validos = df["Comentario"].astype(str).str.len() > 5
        df = df[mask_comentarios_validos]
        
        # Adiciona classificaÃ§Ã£o NPS
        try:
            df["Classificacao_NPS"] = df["Nota"].apply(classificar_nps)
        except Exception as e:
            st.error(f"Erro ao classificar NPS: {str(e)}")
            # Fallback: classificaÃ§Ã£o manual
            df["Classificacao_NPS"] = "NÃ£o classificado"
            for idx, row in df.iterrows():
                try:
                    nota = float(row["Nota"])
                    if nota >= 9:
                        df.at[idx, "Classificacao_NPS"] = "Promotor"
                    elif nota >= 7:
                        df.at[idx, "Classificacao_NPS"] = "Neutro"
                    else:
                        df.at[idx, "Classificacao_NPS"] = "Detrator"
                except:
                    df.at[idx, "Classificacao_NPS"] = "NÃ£o classificado"

        # Exibe estatÃ­sticas bÃ¡sicas
        st.success(f"âœ… Arquivo carregado com sucesso! {len(df)} registros vÃ¡lidos encontrados.")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“Š Total de Registros", len(df))
        with col2:
            st.metric("ğŸ‘ Promotores", len(df[df["Classificacao_NPS"] == "Promotor"]))
        with col3:
            st.metric("ğŸ‘ Detratores", len(df[df["Classificacao_NPS"] == "Detrator"]))

        # === NOVO: DASHBOARD TERMÃ”METRO EMOCIONAL ===
        if len(df) > 0:
            df_com_termometro = gerar_dashboard_termometro(df)

        # Filtros
        st.markdown("### ğŸ” Filtros e VisualizaÃ§Ã£o")
        col1, col2 = st.columns(2)
        
        with col1:
            tipos_questao = ["Todos"] + sorted(df["Tipo_Questao"].dropna().unique().tolist())
            tipo_questao = st.selectbox("Filtrar por tipo de questÃ£o:", tipos_questao)
        
        with col2:
            nps_filter = st.selectbox("Filtrar por classificaÃ§Ã£o NPS:", ["Todos", "Promotor", "Neutro", "Detrator"])

        # AplicaÃ§Ã£o dos filtros
        df_filtrado = df.copy()
        if tipo_questao != "Todos":
            df_filtrado = df_filtrado[df_filtrado["Tipo_Questao"] == tipo_questao]
        if nps_filter != "Todos":
            df_filtrado = df_filtrado[df_filtrado["Classificacao_NPS"] == nps_filter]

        st.info(f"ğŸ“‹ Exibindo {len(df_filtrado)} registros apÃ³s aplicaÃ§Ã£o dos filtros")

        # ExibiÃ§Ã£o dos dados filtrados - convertendo para string para evitar erros do PyArrow
        try:
            df_display = df_filtrado[["OrderId", "Nota", "Classificacao_NPS", "Tipo_Questao", "Comentario", "Motivo_Selecionado"]].copy()
            
            # Converte todas as colunas para string para evitar problemas de tipo
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, use_container_width=True, height=400)
        except Exception as e:
            st.error(f"Erro ao exibir dados: {str(e)}")
            # Fallback: exibe sem formataÃ§Ã£o especial
            st.write(df_filtrado[["OrderId", "Nota", "Classificacao_NPS", "Tipo_Questao", "Comentario", "Motivo_Selecionado"]].head(100))

        # === TERMÃ”METRO PARA DADOS FILTRADOS ===
        if len(df_filtrado) > 0:
            st.markdown("### ğŸŒ¡ï¸ TermÃ´metro dos Dados Filtrados")
            df_filtrado_termometro = gerar_dashboard_termometro(df_filtrado)

        # AnÃ¡lise com IA
        st.markdown("### ğŸ¤– AnÃ¡lise com InteligÃªncia Artificial")
        
        if len(df_filtrado) < 5:
            st.warning("âš ï¸ NÃºmero insuficiente de registros para anÃ¡lise. MÃ­nimo: 5 registros.")
        else:
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info("ğŸ’¡ A IA irÃ¡ analisar os comentÃ¡rios e sugerir novos motivos baseados em padrÃµes identificados")
            with col2:
                n_clusters = st.number_input("NÃºmero de grupos:", min_value=2, max_value=15, value=8)

            if st.button("ğŸ”— Gerar nova sugestÃ£o de motivos por IA", type="primary"):
                # Primeiro, vamos testar a conexÃ£o com a API
                st.info("ğŸ”¬ Testando conexÃ£o com OpenAI...")
                try:
                    test_response = client.embeddings.create(
                        input=["Teste de conexÃ£o"],
                        model="text-embedding-ada-002"
                    )
                    st.success("âœ… ConexÃ£o com OpenAI funcionando!")
                except Exception as test_error:
                    st.error(f"âŒ Falha no teste de conexÃ£o: {str(test_error)}")
                    st.stop()
                
                if len(df_filtrado) > 0:
                    resultado = sugerir_motivos_por_cluster(df_filtrado, n_clusters)
                    
                    if resultado is not None and len(resultado) == 2:
                        sugestoes, df_final = resultado
                        
                        if sugestoes is not None and not sugestoes.empty:
                            # Centraliza o conteÃºdo
                            col_esq, col_centro, col_dir = st.columns([1, 8, 1])
                            
                            with col_centro:
                                st.success("âœ… AnÃ¡lise concluÃ­da!")
                                st.markdown("### ğŸ¯ SugestÃµes de Novos Motivos NPS")
                                
                                # Exibe as sugestÃµes de forma mais organizada
                                st.dataframe(sugestoes, use_container_width=True, hide_index=True)
                                
                                # Download do CSV
                                csv_buffer = io.StringIO()
                                sugestoes.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
                                csv_data = csv_buffer.getvalue().encode("utf-8-sig")
                                
                                # Centraliza o botÃ£o de download
                                col1, col2, col3 = st.columns([2, 4, 2])
                                with col2:
                                    st.download_button(
                                        label="ğŸ“¥ Baixar sugestÃµes em CSV",
                                        data=csv_data,
                                        file_name="sugestoes_motivos_nps.csv",
                                        mime="text/csv",
                                        use_container_width=True
                                    )
                            
                            # Gera relatÃ³rio detalhado (fora da coluna centralizada para usar toda a largura)
                            relatorio_expandido = gerar_relatorio_detalhado(df_filtrado, sugestoes, df_final)
                            
                            # AnÃ¡lise especÃ­fica de detratores
                            analise_detratores = gerar_analise_detratores(df_filtrado, df_final)
                        else:
                            st.error("âŒ NÃ£o foi possÃ­vel gerar as sugestÃµes. Verifique os dados e tente novamente.")
                    else:
                        st.error("âŒ Erro no processamento dos clusters.")
                else:
                    st.warning("âš ï¸ Nenhum registro encontrado com os filtros aplicados.")

    except Exception as e:
        st.error(f"âŒ Erro ao processar o arquivo: {str(e)}")
        st.info("ğŸ’¡ Verifique se o arquivo estÃ¡ no formato correto e contÃ©m as colunas necessÃ¡rias.")

else:
    # InstruÃ§Ãµes quando nÃ£o hÃ¡ arquivo
    st.markdown("""
    ### ğŸ“‹ InstruÃ§Ãµes de Uso
    
    1. **FaÃ§a upload** de um arquivo CSV ou Excel com os dados do NPS
    2. **Visualize o termÃ´metro emocional** para entender o estado dos clientes
    3. **Identifique a OS mais crÃ­tica** para aÃ§Ã£o imediata
    4. **Aplique filtros** por tipo de questÃ£o e classificaÃ§Ã£o NPS
    5. **Execute a anÃ¡lise** com IA para gerar sugestÃµes de motivos
    6. **Baixe os resultados** em formato CSV
    
    #### ğŸ“Š Estrutura Esperada do Arquivo:
    - **Coluna 1**: OrderId (Ordem de ServiÃ§o)
    - **Coluna 2**: Companhia  
    - **Coluna 3**: Secao
    - **Coluna 4**: Tipo_Questao (ex: "Carglass", "Lojista")
    - **Coluna 5**: Nota (0-10)
    - **Coluna 6**: Motivo_Selecionado
    - **Coluna 7**: Comentario
    - **Coluna 9** (opcional): Grupo_Motivo
    
    #### ğŸŒ¡ï¸ Novos Recursos:
    - **TermÃ´metro Emocional**: Classifica clientes em Feliz, Neutro, Atritado ou Extremamente Insatisfeito
    - **IdentificaÃ§Ã£o de OS CrÃ­tica**: Mostra a Ordem de ServiÃ§o do pior comentÃ¡rio para aÃ§Ã£o imediata
    - **Dashboard Visual**: GrÃ¡ficos interativos para anÃ¡lise rÃ¡pida
    
    ### ğŸ“‹ Requirements.txt
    ```txt
    streamlit>=1.28.0
    pandas>=1.5.0
    numpy>=1.24.0
    openai>=1.0.0
    scikit-learn>=1.3.0
    openpyxl>=3.1.0
    plotly>=5.0.0
    ```
    """)
