import streamlit as st
import pandas as pd
import numpy as np
from openai import OpenAI
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min
import io
import plotly.express as px
import plotly.graph_objects as go

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="NPS Insights Carglass", layout="wide")
st.title("üìä An√°lise Inteligente de Coment√°rios NPS - CarGlass")

# Configura√ß√£o da API OpenAI
try:
    # Tenta diferentes nomes de chave que podem estar nos secrets
    api_key = None
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
    elif "openai_api_key" in st.secrets:
        api_key = st.secrets["openai_api_key"]
    elif "OPENAI_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_KEY"]
    
    if api_key is None:
        st.error("üîë Chave da API OpenAI n√£o encontrada. Verifique o arquivo .streamlit/secrets.toml")
        st.info("üí° Certifique-se de que a chave est√° definida como: OPENAI_API_KEY = 'sua_chave_aqui'")
        st.stop()
    
    client = OpenAI(api_key=api_key)
    st.success("‚úÖ Conex√£o com OpenAI estabelecida!")
    
except Exception as e:
    st.error(f"üîë Erro ao configurar OpenAI: {str(e)}")
    st.stop()

def classificar_nps(nota):
    """Classifica a nota NPS em Promotor, Neutro ou Detrator"""
    try:
        nota = float(nota)
        if nota >= 9:
            return "Promotor"
        elif nota >= 7:
            return "Neutro"
        else:
            return "Detrator"
    except (ValueError, TypeError):
        return "N√£o classificado"

def gerar_embeddings_lote(textos, tamanho_lote=20):
    """Gera embeddings em lotes menores para evitar problemas"""
    try:
        todos_embeddings = []
        total_lotes = (len(textos) - 1) // tamanho_lote + 1
        
        # Cria um container fixo para o progresso
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        for i in range(0, len(textos), tamanho_lote):
            lote = textos[i:i+tamanho_lote]
            lote_atual = i // tamanho_lote + 1
            
            # Atualiza progresso sem mover a tela
            progress = lote_atual / total_lotes
            progress_bar.progress(progress)
            status_text.text(f"ü§ñ Processando lote {lote_atual} de {total_lotes} ({len(lote)} coment√°rios)")
            
            response = client.embeddings.create(
                input=lote,
                model="text-embedding-ada-002"
            )
            
            lote_embeddings = [embedding.embedding for embedding in response.data]
            todos_embeddings.extend(lote_embeddings)
        
        # Limpa o progresso
        progress_container.empty()
        return todos_embeddings
        
    except Exception as e:
        st.error(f"Erro no processamento em lotes: {str(e)}")
        return None
def gerar_embeddings(textos):
    """Gera embeddings dos textos usando OpenAI"""
    try:
        # Limpa e valida os textos de forma mais rigorosa
        textos_limpos = []
        for i, texto in enumerate(textos):
            # Converte para string e limpa
            texto_str = str(texto).strip()
            
            # Remove caracteres problem√°ticos
            texto_limpo = texto_str.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
            # Remove caracteres de controle
            texto_limpo = ''.join(char for char in texto_limpo if ord(char) >= 32 or char in '\n\r\t')
            
            # Limita tamanho (OpenAI tem limite de tokens)
            if len(texto_limpo) > 8000:
                texto_limpo = texto_limpo[:8000]
            
            # S√≥ adiciona se tiver conte√∫do v√°lido
            if len(texto_limpo.strip()) >= 10:
                textos_limpos.append(texto_limpo.strip())
        
        if not textos_limpos:
            st.error("‚ùå Nenhum texto v√°lido encontrado para an√°lise.")
            return None
        
        # Container fixo para status
        status_container = st.container()
        with status_container:
            st.info(f"üîÑ Iniciando processamento de {len(textos_limpos)} coment√°rios...")
        
        # Tenta com lotes menores se houver muitos textos
        if len(textos_limpos) > 50:
            result = gerar_embeddings_lote(textos_limpos, tamanho_lote=20)
        else:
            # Para quantidades menores, processa tudo de uma vez
            try:
                response = client.embeddings.create(
                    input=textos_limpos,
                    model="text-embedding-ada-002"
                )
                result = [embedding.embedding for embedding in response.data]
                
            except Exception as api_error:
                st.warning(f"‚ö†Ô∏è Tentando processamento em lotes menores...")
                result = gerar_embeddings_lote(textos_limpos, tamanho_lote=10)
        
        # Atualiza status final
        status_container.empty()
        if result:
            st.success(f"‚úÖ Embeddings gerados com sucesso para {len(result)} textos!")
        
        return result
        
    except Exception as e:
        st.error(f"Erro geral ao gerar embeddings: {str(e)}")
        return None

def sugerir_motivos_por_cluster(df_filtrado, n_clusters=8):
    """Analisa os coment√°rios e sugere novos motivos baseados em clustering"""
    try:
        # Filtra coment√°rios v√°lidos
        df_valido = df_filtrado.copy()
        df_valido = df_valido.dropna(subset=["Comentario"])
        
        # Converte coment√°rios para string e filtra v√°lidos
        df_valido["Comentario"] = df_valido["Comentario"].astype(str)
        
        # Filtra coment√°rios v√°lidos com valida√ß√£o mais rigorosa
        mask_validos = (
            (df_valido["Comentario"] != '') & 
            (df_valido["Comentario"] != 'nan') &
            (df_valido["Comentario"] != 'None') &
            (df_valido["Comentario"].str.len() > 10) &
            (df_valido["Comentario"].str.strip() != '')
        )
        df_valido = df_valido[mask_validos].reset_index(drop=True)
        
        if len(df_valido) < 2:
            st.error("‚ùå N√∫mero insuficiente de coment√°rios v√°lidos para an√°lise.")
            st.info("üí° Dica: Verifique se h√° coment√°rios com pelo menos 10 caracteres no dataset filtrado.")
            return None
        
        if len(df_valido) < n_clusters:
            st.warning(f"‚ö†Ô∏è Coment√°rios dispon√≠veis ({len(df_valido)}) menor que clusters solicitados ({n_clusters}). Ajustando para {max(2, len(df_valido)//2)} clusters.")
            n_clusters = max(2, len(df_valido)//2)
        
        # Prepara lista de textos limpos
        textos = []
        indices_validos = []
        
        for idx, comentario in enumerate(df_valido["Comentario"]):
            texto_limpo = str(comentario).strip()
            if len(texto_limpo) > 10:  # Valida√ß√£o extra
                textos.append(texto_limpo)
                indices_validos.append(idx)
        
        if len(textos) < 2:
            st.error("‚ùå Nenhum coment√°rio v√°lido encontrado ap√≥s limpeza.")
            return None
            
        st.info(f"üìä Analisando {len(textos)} coment√°rios v√°lidos em {n_clusters} grupos.")
        
        # Gera embeddings
        with st.spinner("ü§ñ Gerando embeddings com OpenAI..."):
            embeddings = gerar_embeddings(textos)
        
        if embeddings is None or len(embeddings) == 0:
            return None
        
        # Aplica clustering
        with st.spinner("üîç Realizando an√°lise de clusters..."):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(embeddings)
        
        # Cria DataFrame final apenas com textos que foram processados
        df_final = df_valido.iloc[indices_validos].copy()
        df_final.loc[:, "Cluster"] = labels
        
        # Encontra coment√°rios representativos
        representantes_idx, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)
        
        motivos = []
        for i, idx in enumerate(representantes_idx):
            try:
                linha = df_final.iloc[idx]
                comentario_repr = linha["Comentario"]
                classificacao = linha["Classificacao_NPS"]
                
                # Cria sugest√£o de motivo mais concisa
                comentario_str = str(comentario_repr).strip()
                if len(comentario_str) > 120:
                    sugestao = comentario_str[:117] + "..."
                else:
                    sugestao = comentario_str
                
                # Conta quantos coment√°rios est√£o neste cluster
                count_cluster = len(df_final[df_final["Cluster"] == i])
                
                motivos.append({
                    "Cluster": f"Grupo {i+1}",
                    "Classificacao_NPS": classificacao,
                    "Coment√°rio Representativo": sugestao,
                    "Quantidade de Coment√°rios": count_cluster
                })
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao processar cluster {i+1}: {str(e)}")
                continue
        
        if not motivos:
            st.error("‚ùå N√£o foi poss√≠vel gerar motivos representativos.")
            return None, None
            
        resultado_sugestoes = pd.DataFrame(motivos).sort_values("Cluster")
        return resultado_sugestoes, df_final
    
    except Exception as e:
        st.error(f"Erro na an√°lise de clusters: {str(e)}")
        return None, None

def detectar_problemas_csv(df):
    """Detecta e corrige problemas comuns em arquivos CSV"""
    problemas = []
    
    # Verifica colunas duplicadas
    if df.columns.duplicated().any():
        problemas.append("Colunas duplicadas detectadas")
        df = df.loc[:, ~df.columns.duplicated()]
    
    # Verifica se h√° muitas colunas vazias
    colunas_vazias = df.columns[df.isnull().all()].tolist()
    if colunas_vazias:
        problemas.append(f"Colunas completamente vazias: {len(colunas_vazias)}")
        df = df.drop(columns=colunas_vazias)
    
    # Remove linhas completamente vazias
    linhas_antes = len(df)
    df = df.dropna(how='all')
    linhas_removidas = linhas_antes - len(df)
    if linhas_removidas > 0:
        problemas.append(f"Linhas vazias removidas: {linhas_removidas}")
    
    return df, problemas

def limpar_dados(df):
    """Limpa e padroniza os dados do DataFrame"""
    # Converte colunas para string para evitar problemas de tipo
    colunas_texto = ["Comentario", "Motivo_Selecionado", "Tipo_Questao"]
    for col in colunas_texto:
        if col in df.columns:
            df[col] = df[col].astype(str)
            df[col] = df[col].replace('nan', '')
            df[col] = df[col].replace('<NA>', '')
    
    # Limpa e converte a coluna de nota
    if "Nota" in df.columns:
        df["Nota"] = pd.to_numeric(df["Nota"], errors="coerce")
        df = df.dropna(subset=["Nota"])
        df["Nota"] = df["Nota"].astype(int)
    
    return df

# Interface principal
st.markdown("### üìÅ Upload do Arquivo")
uploaded_file = st.file_uploader(
    "Envie o arquivo Excel ou CSV com os coment√°rios NPS:", 
    type=[".xlsx", ".csv"],
    help="O arquivo deve conter as colunas: Nota, Tipo_Questao, Comentario, Motivo_Selecionado"
)

if uploaded_file:
    try:
        # Leitura do arquivo
        with st.spinner("Carregando arquivo..."):
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file, encoding="utf-8")
            else:
                df = pd.read_excel(uploaded_file, header=1)

        # Verifica√ß√£o e corre√ß√£o de problemas no CSV
        df, problemas = detectar_problemas_csv(df)
        if problemas:
            st.warning("‚ö†Ô∏è Problemas detectados e corrigidos:")
            for problema in problemas:
                st.write(f"‚Ä¢ {problema}")

        # Mostra informa√ß√µes b√°sicas do arquivo
        st.info(f"üìÅ Arquivo carregado: {len(df)} linhas x {len(df.columns)} colunas")
        
        # Exibe as primeiras colunas para debug
        with st.expander("üîç Visualizar estrutura do arquivo"):
            st.write("**Primeiras 10 colunas:**")
            st.write(list(df.columns[:10]))
            st.write("**Amostra dos dados:**")
            st.dataframe(df.head(3))

        # Verifica√ß√£o de colunas m√≠nimas
        if len(df.columns) < 7:
            st.error(f"‚ùå O arquivo possui apenas {len(df.columns)} colunas. S√£o necess√°rias pelo menos 7 colunas.")
            st.info("üìã Estrutura esperada: OrderId, Companhia, Secao, Tipo_Questao, Nota, Motivo_Selecionado, Comentario")
            st.stop()

        # Renomea√ß√£o das colunas
        try:
            col_renames = {
                df.columns[0]: "OrderId",
                df.columns[1]: "Companhia", 
                df.columns[2]: "Secao",
                df.columns[3]: "Tipo_Questao",
                df.columns[4]: "Nota",
                df.columns[5]: "Motivo_Selecionado",
                df.columns[6]: "Comentario"
            }
            
            if len(df.columns) > 11:
                col_renames[df.columns[11]] = "Grupo_Motivo"

            # Renomeia apenas as colunas que existem
            df_renamed = df.rename(columns=col_renames)
            
            # Verifica se o rename funcionou
            required_cols = ["OrderId", "Companhia", "Secao", "Tipo_Questao", "Nota", "Motivo_Selecionado", "Comentario"]
            missing_cols = [col for col in required_cols if col not in df_renamed.columns]
            
            if missing_cols:
                st.error(f"‚ùå Colunas n√£o encontradas ap√≥s renomea√ß√£o: {missing_cols}")
                st.write("**Colunas dispon√≠veis:**", list(df.columns))
                st.stop()
            else:
                df = df_renamed
                
        except Exception as e:
            st.error(f"‚ùå Erro na renomea√ß√£o das colunas: {str(e)}")
            st.write("**Estrutura atual do DataFrame:**")
            st.write(f"N√∫mero de colunas: {len(df.columns)}")
            st.write("Primeiras 10 colunas:", list(df.columns[:10]))
            st.stop()

        # Sele√ß√£o das colunas essenciais
        try:
            colunas_essenciais = ["OrderId", "Companhia", "Secao", "Tipo_Questao", "Nota", "Motivo_Selecionado", "Comentario"]
            if "Grupo_Motivo" in df.columns:
                colunas_essenciais.append("Grupo_Motivo")

            # Verifica se todas as colunas essenciais existem
            colunas_existentes = [col for col in colunas_essenciais if col in df.columns]
            if len(colunas_existentes) < 7:
                st.error(f"‚ùå Nem todas as colunas essenciais foram encontradas.")
                st.write("**Colunas encontradas:**", colunas_existentes)
                st.write("**Colunas necess√°rias:**", colunas_essenciais[:7])
                st.stop()

            df = df[colunas_existentes]
            
        except Exception as e:
            st.error(f"‚ùå Erro ao selecionar colunas essenciais: {str(e)}")
            st.stop()
        
        # Limpeza dos dados
        try:
            df = limpar_dados(df)
        except Exception as e:
            st.error(f"Erro na limpeza dos dados: {str(e)}")
            st.info("Tentando continuar com dados b√°sicos...")
            # Limpeza m√≠nima em caso de erro
            if "Nota" in df.columns:
                df["Nota"] = pd.to_numeric(df["Nota"], errors="coerce")
                df = df.dropna(subset=["Nota"])
            if "Comentario" in df.columns:
                df["Comentario"] = df["Comentario"].astype(str)
        
        # Remove linhas sem coment√°rios
        df = df.dropna(subset=["Comentario"])
        df = df[df["Comentario"].astype(str) != '']
        df = df[df["Comentario"].astype(str) != 'nan']
        
        # Filtra coment√°rios com tamanho m√≠nimo
        mask_comentarios_validos = df["Comentario"].astype(str).str.len() > 5
        df = df[mask_comentarios_validos]
        
        # Adiciona classifica√ß√£o NPS
        try:
            df["Classificacao_NPS"] = df["Nota"].apply(classificar_nps)
        except Exception as e:
            st.error(f"Erro ao classificar NPS: {str(e)}")
            # Fallback: classifica√ß√£o manual
            df["Classificacao_NPS"] = "N√£o classificado"
            for idx, row in df.iterrows():
                try:
                    nota = float(row["Nota"])
                    if nota >= 9:
                        df.at[idx, "Classificacao_NPS"] = "Promotor"
                    elif nota >= 7:
                        df.at[idx, "Classificacao_NPS"] = "Neutro"
                    else:
                        df.at[idx, "Classificacao_NPS"] = "Detrator"
                except:
                    df.at[idx, "Classificacao_NPS"] = "N√£o classificado"

        # Exibe estat√≠sticas b√°sicas
        st.success(f"‚úÖ Arquivo carregado com sucesso! {len(df)} registros v√°lidos encontrados.")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä Total de Registros", len(df))
        with col2:
            st.metric("üëç Promotores", len(df[df["Classificacao_NPS"] == "Promotor"]))
        with col3:
            st.metric("üëé Detratores", len(df[df["Classificacao_NPS"] == "Detrator"]))

        # Filtros
        st.markdown("### üîç Filtros e Visualiza√ß√£o")
        col1, col2 = st.columns(2)
        
        with col1:
            tipos_questao = ["Todos"] + sorted(df["Tipo_Questao"].dropna().unique().tolist())
            tipo_questao = st.selectbox("Filtrar por tipo de quest√£o:", tipos_questao)
        
        with col2:
            nps_filter = st.selectbox("Filtrar por classifica√ß√£o NPS:", ["Todos", "Promotor", "Neutro", "Detrator"])

        # Aplica√ß√£o dos filtros
        df_filtrado = df.copy()
        if tipo_questao != "Todos":
            df_filtrado = df_filtrado[df_filtrado["Tipo_Questao"] == tipo_questao]
        if nps_filter != "Todos":
            df_filtrado = df_filtrado[df_filtrado["Classificacao_NPS"] == nps_filter]

        st.info(f"üìã Exibindo {len(df_filtrado)} registros ap√≥s aplica√ß√£o dos filtros")

        # Exibi√ß√£o dos dados filtrados - convertendo para string para evitar erros do PyArrow
        try:
            df_display = df_filtrado[["Nota", "Classificacao_NPS", "Tipo_Questao", "Comentario", "Motivo_Selecionado"]].copy()
            
            # Converte todas as colunas para string para evitar problemas de tipo
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, use_container_width=True, height=400)
        except Exception as e:
            st.error(f"Erro ao exibir dados: {str(e)}")
            # Fallback: exibe sem formata√ß√£o especial
            st.write(df_filtrado[["Nota", "Classificacao_NPS", "Tipo_Questao", "Comentario", "Motivo_Selecionado"]].head(100))

        # An√°lise com IA
        st.markdown("### ü§ñ An√°lise com Intelig√™ncia Artificial")
        
        if len(df_filtrado) < 5:
            st.warning("‚ö†Ô∏è N√∫mero insuficiente de registros para an√°lise. M√≠nimo: 5 registros.")
        else:
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info("üí° A IA ir√° analisar os coment√°rios e sugerir novos motivos baseados em padr√µes identificados")
            with col2:
                n_clusters = st.number_input("N√∫mero de grupos:", min_value=2, max_value=15, value=8)

                if st.button("üîó Gerar nova sugest√£o de motivos por IA", type="primary"):
                    # Primeiro, vamos testar a conex√£o com a API
                    st.info("üî¨ Testando conex√£o com OpenAI...")
                    try:
                        test_response = client.embeddings.create(
                            input=["Teste de conex√£o"],
                            model="text-embedding-ada-002"
                        )
                        st.success("‚úÖ Conex√£o com OpenAI funcionando!")
                    except Exception as test_error:
                        st.error(f"‚ùå Falha no teste de conex√£o: {str(test_error)}")
                        st.stop()
                    
                    if len(df_filtrado) > 0:
                        sugestoes = sugerir_motivos_por_cluster(df_filtrado, n_clusters)
                        
def gerar_relatorio_detalhado(df_filtrado, sugestoes, df_final):
    """Gera um relat√≥rio detalhado da an√°lise para apresenta√ß√£o √† diretoria"""
    
    st.markdown("---")
    st.markdown("## üìä Relat√≥rio Executivo da An√°lise NPS")
    
    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_comentarios = len(df_filtrado)
        st.metric("üìù Total Analisado", f"{total_comentarios:,}")
    
    with col2:
        promotores = len(df_filtrado[df_filtrado["Classificacao_NPS"] == "Promotor"])
        perc_promotores = (promotores/total_comentarios)*100 if total_comentarios > 0 else 0
        st.metric("üëç Promotores", f"{promotores:,}", f"{perc_promotores:.1f}%")
    
    with col3:
        detratores = len(df_filtrado[df_filtrado["Classificacao_NPS"] == "Detrator"])
        perc_detratores = (detratores/total_comentarios)*100 if total_comentarios > 0 else 0
        st.metric("üëé Detratores", f"{detratores:,}", f"{perc_detratores:.1f}%")
    
    with col4:
        nps_score = perc_promotores - perc_detratores
        st.metric("üéØ NPS Score", f"{nps_score:.1f}")
    
    # An√°lise por cluster
    st.markdown("### üîç An√°lise Detalhada por Grupo")
    
    # Cria tabs para diferentes an√°lises
    tab1, tab2, tab3, tab4 = st.tabs(["üìã Resumo Grupos", "üìà An√°lise Quantitativa", "üí¨ Coment√°rios Representativos", "üìä Distribui√ß√£o"])
    
    with tab1:
        st.markdown("#### Grupos Identificados pela IA")
        
        # Adiciona mais colunas √† tabela de sugest√µes
        sugestoes_expandidas = sugestoes.copy()
        sugestoes_expandidas["% do Total"] = (sugestoes_expandidas["Quantidade de Coment√°rios"] / total_comentarios * 100).round(1)
        
        # Reordena as colunas
        sugestoes_display = sugestoes_expandidas[["Cluster", "Classificacao_NPS", "Quantidade de Coment√°rios", "% do Total", "Coment√°rio Representativo"]]
        
        st.dataframe(sugestoes_display, use_container_width=True, hide_index=True)
    
    with tab2:
        st.markdown("#### Distribui√ß√£o por Classifica√ß√£o NPS")
        
        # An√°lise por classifica√ß√£o
        analise_nps = df_filtrado.groupby("Classificacao_NPS").size().reset_index(name="Quantidade")
        analise_nps["Percentual"] = (analise_nps["Quantidade"] / total_comentarios * 100).round(1)
        
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(analise_nps, hide_index=True)
        
        with col2:
            # Principais motivos atuais
            if "Motivo_Selecionado" in df_filtrado.columns:
                top_motivos = df_filtrado["Motivo_Selecionado"].value_counts().head(5)
                st.markdown("**Top 5 Motivos Atuais:**")
                for motivo, count in top_motivos.items():
                    perc = (count/total_comentarios)*100
                    st.write(f"‚Ä¢ {motivo}: {count} ({perc:.1f}%)")
    
    with tab3:
        st.markdown("#### Coment√°rios Mais Representativos por Grupo")
        
        for _, row in sugestoes.iterrows():
            cluster_num = int(row["Cluster"].split()[-1])
            comentarios_cluster = df_final[df_final["Cluster"] == cluster_num-1]
            
            with st.expander(f"{row['Cluster']} - {row['Classificacao_NPS']} ({row['Quantidade de Coment√°rios']} coment√°rios)"):
                st.write(f"**Coment√°rio Principal:** {row['Coment√°rio Representativo']}")
                
                # Mostra mais alguns coment√°rios do cluster
                if len(comentarios_cluster) > 1:
                    st.write("**Outros coment√°rios similares:**")
                    outros_comentarios = comentarios_cluster["Comentario"].head(3).tolist()
                    for i, comentario in enumerate(outros_comentarios[:3], 1):
                        if comentario != row["Coment√°rio Representativo"]:
                            st.write(f"{i}. {str(comentario)[:150]}...")
    
    with tab4:
        st.markdown("#### An√°lise de Distribui√ß√£o")
        
        # Cria visualiza√ß√£o dos grupos
        # Gr√°fico de barras dos grupos
        fig_grupos = px.bar(
            sugestoes_expandidas, 
            x="Cluster", 
            y="Quantidade de Coment√°rios",
            color="Classificacao_NPS",
            title="Distribui√ß√£o de Coment√°rios por Grupo",
            color_discrete_map={
                "Promotor": "#2E8B57",
                "Neutro": "#FFD700", 
                "Detrator": "#DC143C"
            }
        )
        st.plotly_chart(fig_grupos, use_container_width=True)
        
        # Insights principais
        st.markdown("#### üéØ Principais Insights")
        
        grupo_maior = sugestoes_expandidas.loc[sugestoes_expandidas["Quantidade de Coment√°rios"].idxmax()]
        grupo_detrator = sugestoes_expandidas[sugestoes_expandidas["Classificacao_NPS"] == "Detrator"]
        
        insights = [
            f"‚Ä¢ **Maior grupo identificado:** {grupo_maior['Cluster']} com {grupo_maior['Quantidade de Coment√°rios']:,} coment√°rios ({grupo_maior['% do Total']:.1f}% do total)"
        ]
        
        # Destaque especial para grupos de detratores
        if not grupo_detrator.empty:
            # Encontra o maior grupo de detratores
            maior_detrator = grupo_detrator.loc[grupo_detrator["Quantidade de Coment√°rios"].idxmax()]
            total_detratores_grupos = grupo_detrator["Quantidade de Coment√°rios"].sum()
            perc_detratores_grupos = (total_detratores_grupos / total_comentarios) * 100
            
            insights.extend([
                f"‚Ä¢ **üö® ALERTA CR√çTICO - {maior_detrator['Cluster']}:** {maior_detrator['Quantidade de Coment√°rios']:,} detratores ({(maior_detrator['Quantidade de Coment√°rios']/total_comentarios)*100:.1f}%)",
                f"  ‚îî‚îÄ **Problema:** {maior_detrator['Coment√°rio Representativo']}",
                f"‚Ä¢ **Total de grupos de detratores:** {len(grupo_detrator)} grupos com {total_detratores_grupos:,} coment√°rios ({perc_detratores_grupos:.1f}%)",
                f"‚Ä¢ **Classifica√ß√£o predominante:** {sugestoes['Classificacao_NPS'].mode()[0]}"
            ])
        else:
            insights.append(f"‚Ä¢ **Classifica√ß√£o predominante:** {sugestoes['Classificacao_NPS'].mode()[0]}")
        
        insights.append(f"‚Ä¢ **NPS Score atual:** {nps_score:.1f} ({'Excelente' if nps_score >= 50 else 'Bom' if nps_score >= 0 else 'Ruim'})")
        
        for insight in insights:
            if "üö® ALERTA CR√çTICO" in insight:
                st.markdown(f"<div style='background-color: #ffebee; padding: 10px; border-radius: 5px; border-left: 5px solid #f44336;'>{insight}</div>", unsafe_allow_html=True)
            else:
                st.markdown(insight)
        
        # Recomenda√ß√µes
        st.markdown("#### üí° Recomenda√ß√µes Estrat√©gicas")
        
        recomendacoes = [
            "üìå **Manter pontos fortes:** Refor√ßar pr√°ticas que geram coment√°rios positivos nos grupos de promotores",
            "üéØ **Focar em melhorias:** Priorizar a√ß√µes corretivas nos grupos de detratores identificados",
            "üìä **Monitoramento cont√≠nuo:** Implementar acompanhamento regular usando estes grupos como baseline",
            "üîÑ **Atualiza√ß√£o de motivos:** Considerar substituir motivos atuais pelos sugeridos pela IA para maior precis√£o"
        ]
        
        for rec in recomendacoes:
            st.markdown(rec)
    
def gerar_analise_detratores(df_filtrado, df_final):
    """Gera an√°lise espec√≠fica e detalhada dos detratores"""
    
    detratores = df_filtrado[df_filtrado["Classificacao_NPS"] == "Detrator"]
    
    if len(detratores) == 0:
        st.info("‚úÖ Nenhum detrator encontrado nos dados filtrados.")
        return
    
    st.markdown("---")
    st.markdown("## üö® An√°lise Cr√≠tica de Detratores")
    st.markdown("*Esta se√ß√£o foca nos clientes mais insatisfeitos para a√ß√µes priorit√°rias*")
    
    # M√©tricas cr√≠ticas
    col1, col2, col3, col4 = st.columns(4)
    
    total_detratores = len(detratores)
    total_geral = len(df_filtrado)
    perc_detratores = (total_detratores / total_geral) * 100
    
    with col1:
        st.metric("üî• Total Detratores", f"{total_detratores:,}", f"{perc_detratores:.1f}% do total")
    
    with col2:
        nota_media = detratores["Nota"].mean()
        st.metric("üìâ Nota M√©dia", f"{nota_media:.1f}", "Cr√≠tico se < 5")
    
    with col3:
        notas_zero = len(detratores[detratores["Nota"] == 0])
        perc_zero = (notas_zero / total_detratores) * 100 if total_detratores > 0 else 0
        st.metric("üí• Notas 0", f"{notas_zero}", f"{perc_zero:.1f}%")
    
    with col4:
        if "df_final" in locals() and "Cluster" in df_final.columns:
            clusters_detratores = len(df_final[df_final["Classificacao_NPS"] == "Detrator"]["Cluster"].unique())
            st.metric("üéØ Grupos Detratores", clusters_detratores)
        else:
            st.metric("üéØ Grupos Detratores", "N/A")
    
    # Tabs para an√°lise detalhada
    tab1, tab2, tab3, tab4 = st.tabs(["üî• Principais Problemas", "üìä Distribui√ß√£o", "üí¨ Coment√°rios Cr√≠ticos", "‚ö° Plano de A√ß√£o"])
    
    with tab1:
        st.markdown("### üéØ Principais Motivos de Insatisfa√ß√£o")
        
        if "Motivo_Selecionado" in detratores.columns:
            # Top problemas dos detratores
            problemas = detratores["Motivo_Selecionado"].value_counts().head(10)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("#### Top 10 Motivos de Detratores")
                for i, (motivo, count) in enumerate(problemas.items(), 1):
                    perc = (count / total_detratores) * 100
                    
                    # Destaca o principal problema
                    if i == 1:
                        st.markdown(f"**üî¥ {i}. {motivo}**")
                        st.markdown(f"   üìä **{count:,} casos ({perc:.1f}% dos detratores)**")
                        st.markdown(f"   üö® **PRIORIDADE M√ÅXIMA**")
                    elif i <= 3:
                        st.markdown(f"**üü° {i}. {motivo}**")
                        st.markdown(f"   üìä {count:,} casos ({perc:.1f}%)")
                    else:
                        st.markdown(f"{i}. {motivo}: {count:,} casos ({perc:.1f}%)")
            
            with col2:
                # An√°lise do problema principal
                problema_principal = problemas.index[0]
                casos_principais = detratores[detratores["Motivo_Selecionado"] == problema_principal]
                
                st.markdown("#### üîç An√°lise do Problema #1")
                st.metric("Casos", len(casos_principais))
                
                if len(casos_principais) > 0:
                    nota_media_problema = casos_principais["Nota"].mean()
                    st.metric("Nota M√©dia", f"{nota_media_problema:.1f}")
                    
                    # Distribui√ß√£o de notas do problema principal
                    distribuicao_notas = casos_principais["Nota"].value_counts().sort_index()
                    st.markdown("**Distribui√ß√£o de Notas:**")
                    for nota, count in distribuicao_notas.items():
                        st.write(f"Nota {nota}: {count} casos")
    
    with tab2:
        st.markdown("### üìà Distribui√ß√£o e Tend√™ncias")
        
        # Gr√°fico de distribui√ß√£o de notas dos detratores
        fig_notas = px.histogram(
            detratores, 
            x="Nota", 
            title="Distribui√ß√£o de Notas - Detratores",
            color_discrete_sequence=["#DC143C"]
        )
        fig_notas.update_layout(xaxis_title="Nota NPS", yaxis_title="Quantidade")
        st.plotly_chart(fig_notas, use_container_width=True)
        
        # An√°lise por tipo de quest√£o se dispon√≠vel
        if "Tipo_Questao" in detratores.columns:
            st.markdown("#### üìã Detratores por Tipo de Quest√£o")
            tipo_questao = detratores["Tipo_Questao"].value_counts()
            
            fig_tipo = px.pie(
                values=tipo_questao.values,
                names=tipo_questao.index,
                title="Distribui√ß√£o de Detratores por Tipo"
            )
            st.plotly_chart(fig_tipo, use_container_width=True)
    
    with tab3:
        st.markdown("### üí¨ Coment√°rios Mais Cr√≠ticos")
        
        # Coment√°rios com notas 0-2 (mais cr√≠ticos)
        criticos = detratores[detratores["Nota"] <= 2].sort_values("Nota")
        
        if len(criticos) > 0:
            st.markdown(f"#### üö® {len(criticos)} Coment√°rios Extremamente Cr√≠ticos (Notas 0-2)")
            
            for idx, row in criticos.head(5).iterrows():
                with st.expander(f"Nota {row['Nota']} - {row.get('Motivo_Selecionado', 'N/A')}"):
                    st.write(f"**Coment√°rio:** {row['Comentario']}")
                    if "Tipo_Questao" in row:
                        st.write(f"**Tipo:** {row['Tipo_Questao']}")
                    if "Companhia" in row:
                        st.write(f"**Seguradora:** {row['Companhia']}")
        
        # Coment√°rios do maior grupo de detratores (se existir an√°lise de clusters)
        st.markdown("#### üéØ Coment√°rios do Maior Grupo de Detratores")
        if "df_final" in locals() and "Cluster" in df_final.columns:
            detratores_clustered = df_final[df_final["Classificacao_NPS"] == "Detrator"]
            if len(detratores_clustered) > 0:
                maior_cluster = detratores_clustered["Cluster"].value_counts().index[0]
                comentarios_cluster = detratores_clustered[detratores_clustered["Cluster"] == maior_cluster]
                
                st.write(f"**Grupo {maior_cluster + 1} - {len(comentarios_cluster)} coment√°rios**")
                for comentario in comentarios_cluster["Comentario"].head(3):
                    st.write(f"‚Ä¢ {comentario}")
    
    with tab4:
        st.markdown("### ‚ö° Plano de A√ß√£o Imediato")
        
        st.markdown("#### üö® A√ß√µes Priorit√°rias (0-30 dias)")
        
        acoes_imediatas = [
            "üéØ **Foco no problema #1**: Resolver urgentemente as dificuldades de agendamento",
            "üìû **Central de atendimento**: Refor√ßar treinamento da equipe para agendamentos",
            "üîß **Sistema de agendamento**: Revisar e melhorar a plataforma/processo",
            "üì± **M√∫ltiplos canais**: Facilitar agendamento por telefone, WhatsApp e site",
            "‚è∞ **Prazos claros**: Estabelecer SLA m√°ximo para agendamento (ex: 24h)"
        ]
        
        for acao in acoes_imediatas:
            st.markdown(acao)
        
        st.markdown("#### üìà A√ß√µes de M√©dio Prazo (30-90 dias)")
        
        acoes_medio_prazo = [
            "üè™ **Expans√£o da rede**: Avaliar abertura de lojas em regi√µes deficit√°rias",
            "ü§ñ **Automa√ß√£o**: Implementar agendamento autom√°tico com confirma√ß√£o",
            "üìä **Monitoramento**: Dashboard em tempo real dos agendamentos",
            "üéì **Treinamento**: Capacita√ß√£o cont√≠nua das equipes de atendimento",
            "üìû **Callback**: Sistema de retorno autom√°tico para casos n√£o resolvidos"
        ]
        
        for acao in acoes_medio_prazo:
            st.markdown(acao)
        
        # ROI estimado
        st.markdown("#### üí∞ Impacto Financeiro Estimado")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**üí∏ Custo atual dos detratores:**")
            st.write(f"‚Ä¢ {total_detratores:,} clientes insatisfeitos")
            st.write(f"‚Ä¢ Potencial perda de receita")
            st.write(f"‚Ä¢ Impacto na reputa√ß√£o da marca")
        
        with col2:
            st.markdown("**üíπ Benef√≠cio da melhoria:**")
            st.write(f"‚Ä¢ Convers√£o de {total_detratores//2:,} detratores em neutros")
            st.write(f"‚Ä¢ Melhoria do NPS em ~{(total_detratores//2/total_geral)*100:.1f} pontos")
            st.write(f"‚Ä¢ Redu√ß√£o de reclama√ß√µes e cancelamentos")
    
    return detratores
                            st.success("‚úÖ An√°lise conclu√≠da!")
                            st.markdown("### üéØ Sugest√µes de novos motivos")
                            
                            # Exibe as sugest√µes
                            st.dataframe(sugestoes, use_container_width=True)
                            
                            # Download do CSV
                            csv_buffer = io.StringIO()
                            sugestoes.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
                            csv_data = csv_buffer.getvalue().encode("utf-8-sig")
                            
                            st.download_button(
                                label="üì• Baixar sugest√µes em CSV",
                                data=csv_data,
                                file_name="sugestoes_motivos_nps.csv",
                                mime="text/csv"
                            )
                            
                            # Insights adicionais
                            st.markdown("### üìà Insights Principais")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("üî¢ Grupos Identificados", len(sugestoes))
                            with col2:
                                classificacao_mais_comum = sugestoes["Classificacao_NPS"].mode()[0]
                                st.metric("üìä Classifica√ß√£o Predominante", classificacao_mais_comum)
                        else:
                            st.error("‚ùå N√£o foi poss√≠vel gerar as sugest√µes. Verifique os dados e tente novamente.")
                    else:
                        st.warning("‚ö†Ô∏è Nenhum registro encontrado com os filtros aplicados.")

    except Exception as e:
        st.error(f"‚ùå Erro ao processar o arquivo: {str(e)}")
        st.info("üí° Verifique se o arquivo est√° no formato correto e cont√©m as colunas necess√°rias.")

else:
    # Instru√ß√µes quando n√£o h√° arquivo
    st.markdown("""
    ### üìã Instru√ß√µes de Uso
    
    1. **Fa√ßa upload** de um arquivo CSV ou Excel com os dados do NPS
    2. **Aplique filtros** por tipo de quest√£o e classifica√ß√£o NPS
    3. **Execute a an√°lise** com IA para gerar sugest√µes de motivos
    4. **Baixe os resultados** em formato CSV
    
    #### üìä Estrutura Esperada do Arquivo:
    - **Coluna 1**: OrderId
    - **Coluna 2**: Companhia  
    - **Coluna 3**: Secao
    - **Coluna 4**: Tipo_Questao (ex: "Carglass", "Lojista")
    - **Coluna 5**: Nota (0-10)
    - **Coluna 6**: Motivo_Selecionado
    - **Coluna 7**: Comentario
    - **Coluna 12** (opcional): Grupo_Motivo
    """)
